---
date: 2025-01-01
layout: post
title: "What it means to be intelligent"
tags: [ai,intelligence,llm]
---



## What Does It Mean to Be Intelligent?

### LLMs: Word Calculators or Something More?

Large Language Models (LLMs) like GPT-4 are often described as "word calculators":

- They don't have an inherent understanding of the world.
- They can't reason in the human sense.
- They can't set their own goals or desires.

Yet, from the seemingly simple objective of next-word prediction, we've seen a host of emergent properties. LLMs can:
- Write code and poetry
- Summarize complex documents
- Pass professional exams
- Hold conversations that feel intelligent

These capabilities make LLMs appear very intelligent, even if their underlying mechanism is just statistical pattern matching.

**Reference:** [Sparks of Artificial General Intelligence: Early experiments with GPT-4 (Microsoft)](https://arxiv.org/abs/2303.12712)

---

### From Philosophy to Experiment: The Chinese Room

The [Chinese Room](https://en.wikipedia.org/wiki/Chinese_room) is a famous thought experiment by philosopher John Searle. Imagine a person who doesn't understand Chinese locked in a room. They receive Chinese characters and use a rulebook (written in English) to produce appropriate Chinese responses. To an outside observer, it seems like the person understands Chinese, but in reality, they're just manipulating symbols.

Today's LLMs are a lot like the Chinese Room: they manipulate symbols (words) based on rules (statistical patterns) without true understanding. Yet, the output can be so convincing that it raises the question: does understanding matter if the results are useful?

**Further reading:**
- [Turing Test](https://en.wikipedia.org/wiki/Turing_test)
- [Searle's Chinese Room Argument](https://plato.stanford.edu/entries/chinese-room/)

---

### Does It Matter If LLMs Aren't "Truly" Intelligent?

Some leading AI researchers, like Yann LeCun, argue that scaling up LLMs won't get us to Artificial General Intelligence (AGI). They believe something architecturally different is needed—LLMs are just "word calculators."

But does it matter, at least for practical purposes?

- If a sufficiently trained model can reason about things (even if it's just next-word prediction) and the reasoning is correct, could we consider that as a form of intelligence?
- Many emergent properties of LLMs can be explained this way. If a system works as per our observations, we treat it as correct—just as in science, where models are updated as new evidence comes in.

**Reference:**
- [Yann LeCun on the limits of scaling LLMs](https://www.technologyreview.com/2023/06/28/1075637/yann-lecun-meta-ai-chief-interview/)

---

### Economic and Societal Impact

Setting aside philosophical debates, the economic implications of AI and LLMs are already profound. The economy doesn't run on "truth"—it runs on what people believe and value (much like the stock market).

LLMs are already:
- Automating customer support
- Assisting in legal and medical research
- Powering new tools for writing, coding, and creativity

The potency of AI and LLMs can't be underestimated, even as we strive for more robust and truly intelligent systems.

**Further reading:**
- [The Economic Case for Generative AI](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)
- [AI and the Future of Work (Brookings)](https://www.brookings.edu/articles/ai-and-the-future-of-work/)

---

### Final Thoughts

Whether or not LLMs are "truly" intelligent, their impact is real and growing. As we continue to observe and experiment, our definitions of intelligence—and our expectations for machines—may evolve as well.

### Once philosophical musings, Now: experimental stuff

[Chinese room](https://en.wikipedia.org/wiki/Chinese_room) was a thought experiment ..... (complete this)
Today's LLMs are sort of like the 'chinese box'

### But does it matter?
LLMs might not lead us to AGI. There are voices by prominent scientists like yann le cunn who insist that laws of scaling won't get us to AGI (if there is such thing) and we would need something architecturally different. 'Word Calculators' are not truly intelligent.

But does it matter (at least in the practical sense)
= if a sufficiently trained model can 'reason' about things by virtue of next word prediction and if that reasoning is correct: could we consider that as being intelligent (chinese room)
= lot of emergent properties that have come out of LLM can be reasoned in the similar way. If we have a system that works as per our observations of the time we can consider that as being correct and as we have more observations we modify the system and our beliefs. That's how scientific research and discoveries have always worked.


### It's role in the economy
Setting aside all the philosophical and technical arguments what are the economic implications of the ongoing boom in AI, we can already see the economic impacts. Economy doesn't work on 'truth', it works based on what majority of the people believe. (just like how stock market works). So we can definitely not undermine the potency of AI or LLM but in the same time strive for better.